{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science 101\n",
    "This problem and dataset are taken from a paper that studied how choices made while analyzing data by different data science teams could incluence the results: \n",
    "\n",
    "[Many analysts, one dataset: Making transparent how variations in analytical choices affect results](https://osf.io/gvm2z/)\n",
    "\n",
    "This particular approach is in part based on the tutorial _Exploratory Data Analysis in Python_, presented at [PyCon2017](https://github.com/cmawer/pycon-2017-eda-tutorial) which is considerably more thorough (if you are interested)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We’re going to explore a dataset describing the players who played in the 2012-13 European football (soccer) professional leagues. Data about the players’ ages, heights, weights, position, skintone rating, and more were included. Focus on exploring the data to find actionable insights, with an overarching goal of answering the following question: **“Are soccer referees more likely to give red cards to dark skin toned players than light skin toned players?”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "The dataset is a detailed list of 146,028 dyads (referee-player pairs) including details from the players, referee's, etc. The readme on the website details tyhe data:\n",
    "```\n",
    "From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2,053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3,147) that these players played under in their professional career (see Figure 1). We created a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    "```\n",
    "![](dataDescription.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis overview and general tips\n",
    "- Before plotting/joining/doing something, have a question or hypothesis that you want to investigate\n",
    "- Next it is a good idea to get a general sense for what the data looks like\n",
    "- Draw a plot of what you want to see on paper to sketch the idea\n",
    "- Write it down, then make the plan on how to get there\n",
    "- How do you know you aren't fooling yourself\n",
    "- What else can I check if this is actually true?\n",
    "- What evidence could there be that it's wrong?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "The csv file included with the material includes ~150k player/referee pairs (or 'dyads' as the documentation refers to them).  Memory usage is moderate, at just over 30 MB so we won't worry too much about memory management at present.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('redcard.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "#data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand how the data's organized\n",
    "The dataset is a single file with every interaction between **referee** and **player** as a single row. In other words: Referee A refereed Player B in, say, 10 games, and gave 2 redcards during those 10 games. Then there would be a unique row in the dataset that said:\n",
    "\n",
    "Referee A, Player B, 2 redcards, ... \n",
    "\n",
    "This has several implications that make this first step to understanding and dealing with this data a bit tricky. First, is that the information about Player B is repeated each time -- meaning:\n",
    "\n",
    "### If we did a simple average of some metric of we would likely get a misleading result by double counting.\n",
    "\n",
    "For example, asking \"what is the average weight of the players?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.height.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.groupby('playerShort').height.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating data health\n",
    "It is a good idea to quickly explore the dataset to understand the overall health. We want to gauge:\n",
    "- Amount of missing data\n",
    "- Class imbalances\n",
    "- Duplicates/repetition\n",
    "- etc.\n",
    "\n",
    "As a first measure of the data quality we check for empty fields in entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_vals = pd.concat([df.isnull().sum(),100*df.isnull().sum()/df.shape[0]],axis=1)\n",
    "null_vals.columns = ['n_missing_vals','perc_missing']\n",
    "null_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several missing entries in the different categories. In particular, there is missing information on the players skin color, the attribute we want to study.  We can also visualize the distribution of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data: skin color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that roughly 15% of players are missing information on their skin color from one or two of the raters. These should be excluded if we want to explore the correlation between these and the number of red cards.  Lets check the instances where we only have one rater value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players  = df.groupby('playerShort')\n",
    "print('All players: ', len(players), ' and ', len(df), ' entries')\n",
    "print('Missing rater1 score: ', len(df[df.rater1.isnull()].groupby('playerShort')))\n",
    "print('Missing rater2 score: ', len(df[df.rater2.isnull()].groupby('playerShort')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_skin_tone_rating = np.logical_xor(df.rater1.isnull(),df.rater2.isnull())\n",
    "print('Missing one, but not the other: ', one_skin_tone_rating.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's fix the data frame\n",
    "Good news! Entries have two or no entries for skin color. Let's remove these entries and understand the relationship between the raters. We can check the correlation between the two raters scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.rater1.notnull()]\n",
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between the two raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rater scores in heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(pd.crosstab(df.rater1, df.rater2), cmap='Blues', annot=True, fmt='d', ax=ax)\n",
    "ax.set_title(\"Correlation between Rater 1 and Rater 2\\n\")\n",
    "fig.tight_layout()\n",
    "# make table with correlation as well\n",
    "(df[['rater1','rater2']].corr()**2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More good news! \n",
    "The two skin tone scores are highly correlated. We can start by engineering our first feature and simply take the average of both scores and take a look at the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skin'] = df[['rater1','rater2']].mean(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the skintone rating look like? European teams are mostly white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skintone = df.groupby('playerShort').skin.mean()\n",
    "sns.distplot(skintone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other player correlations\n",
    "Just to illustrate lets take a look at other pairwise relationships in player attributes. Lets create a second dataframe with only the players information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_index = 'playerShort'\n",
    "player_cols = [#'player', # drop player name, we have unique identifier\n",
    "               'birthday',\n",
    "               'height',\n",
    "               'weight',\n",
    "               'position',\n",
    "               'photoID',\n",
    "                'skin'\n",
    "              ]\n",
    "players = df.groupby('playerShort').agg({col:'max' for col in player_cols})\n",
    "players.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "pd.tools.plotting.scatter_matrix(players[['height', 'weight', 'skin']], alpha=0.2, diagonal='hist', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick detour: weight vs. height\n",
    "As expected, there is a clear correlation between the weight and height of players. Lets focus on this specific pair to extract a relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "players1 = players[players.height.notnull()]\n",
    "players1 = players1[players1.weight.notnull()]\n",
    "\n",
    "X = np.array(players1.weight).reshape(-1,1)\n",
    "y = np.array(players1.height).reshape(-1,1)\n",
    "reg = LinearRegression().fit(X,y)\n",
    "print(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.regplot('weight', 'height', data=players, ax=ax)\n",
    "ax.set_ylabel(\"Height [cm]\")\n",
    "ax.set_xlabel(\"Weight [kg]\")\n",
    "fig.tight_layout()\n",
    "fig.text(0.1,0.8, 'y = %0.2lf x + %0.2lf' %(reg.coef_ , reg.intercept_), fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positions\n",
    "It is possible that the player position has a strong influece on the number of cards as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "players.position.value_counts(dropna=False).plot(kind='barh', ax=ax)\n",
    "ax.set_xlabel('Position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify positions\n",
    "In order to use this information later, lets split the positions into four categories. Modify th original datframe that has "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense = ['Center Back','Defensive Midfielder', 'Left Fullback', 'Right Fullback', ]\n",
    "midfield = ['Right Midfielder', 'Center Midfielder', 'Left Midfielder',]\n",
    "forward = ['Attacking Midfielder', 'Left Winger', 'Right Winger', 'Center Forward']\n",
    "keeper = 'Goalkeeper'\n",
    "\n",
    "# modifying dataframe -- adding the aggregated position categorical position_agg\n",
    "df.loc[df['position'].isin(defense), 'position_agg'] = \"Defense\"\n",
    "df.loc[df['position'].isin(midfield), 'position_agg'] = \"Midfield\"\n",
    "df.loc[df['position'].isin(forward), 'position_agg'] = \"Forward\"\n",
    "df.loc[df['position'].eq(keeper), 'position_agg'] = \"Keeper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_index = 'playerShort'\n",
    "player_cols = ['birthday',\n",
    "               'height',\n",
    "               'weight',\n",
    "               'position_agg',\n",
    "               'redCards',\n",
    "                'skin'\n",
    "              ]\n",
    "players = df.groupby('playerShort').agg({col:'max' for col in player_cols})\n",
    "players.groupby('position_agg').redCards.mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No statistically significant difference, though defense is more likely to have red cards...surprising that Keepers have a decent amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data: refs and red cards\n",
    "Most games have few red cards, i.e. the data set is very unbalanced, especially for cases where a player receives two.  We also have a second scenario where a player receives a red card due to multiple yellow cards. Let't collapse these into a single field. At present we can look at the average number of red cards each player receives per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_reds'] = (df.redCards + df.yellowReds)/df.games\n",
    "plt.hist(df.groupby('playerShort').total_reds.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.redCards.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost all of the players appear with more than one referee\n",
    "print('% of players with multiple refs: {:.4f}'.format(sum(df.playerShort.duplicated())/df.shape[0]))\n",
    "# The same (but to a slightly lesser degree) is true for refs\n",
    "print('% of refs with multiple players: {:.4f}'.format(sum(df.refNum.duplicated())/df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store categorical data as the appropriate data type\n",
    "categorical_features = ['playerShort','club','leagueCountry','position','refNum','refCountry']\n",
    "df[categorical_features] = df[categorical_features].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection/engineering\n",
    "Generally speaking we would like to reduce the number of features to the bare minimum needed to explain the data.\n",
    "\n",
    "First of all, as we saw, the skin tone scores from both raters are hgihly correlated so we can average them. We make a copy of the data frame so we don't breat anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to drop the full names of players as this provides little information of use, we should first verify that that the player short names are unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that there is a 1:1 mapping from short to full name before dropping full name\n",
    "flag_non_unique = False\n",
    "for player_short in df.playerShort.unique():\n",
    "    if df.player[df.playerShort==player_short].nunique() != 1:\n",
    "        print('{} maps to multiple values'.format(player_short))\n",
    "        flag_non_unique = True\n",
    "if not flag_non_unique:\n",
    "    print('1:1 mapping')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['player','birthday','photoID','yellowCards','rater1','rater2','yellowReds','redCards','games',\\\n",
    "                   'Alpha_3','nIAT','seIAT','nExp','seExp','playerShort','refCountry']\n",
    "# features_to_drop = ['player','birthday','photoID','rater1','rater2','games',\\\n",
    "#                    'Alpha_3','nIAT','seIAT','nExp','seExp','playerShort','refCountry']\n",
    "df_ = df.drop(features_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick QA\n",
    "Just check the shape of returned data frame and some histograms to verify that the data is still good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.shape\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of numerical variables\n",
    "_ = df_.select_dtypes(['float64', 'int64']).hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks fine. Even the weight, with a max of exactly 100 kg, looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_.corr()**2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At first glance it doesn't look like skin tone correlated very heavily with anything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of unused categories\n",
    "categorical_features = df_.select_dtypes('category').columns\n",
    "df_[categorical_features] = df_[categorical_features].apply(lambda x: x.cat.remove_unused_categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.select_dtypes('category').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Now let's see if we can use machine learning to predict establish weather or not the color of a players skin will influence the likelihood of receiving a red card.  For this we will use the readom forest implementation included in the python package [scikit-learn](http://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we drop the entries with missing values, and drop the information regarding the ref and sprots club. We make a copy since we might want to evaluate the fairness of referees in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdm_frst = df_.dropna()\n",
    "df_rdm_frst = df_rdm_frst.drop(['refNum','club'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdm_frst.select_dtypes('category').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdm_frst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we input prepare the inputs and labels for the model.  The number of total red cards per game will be used as our label (i.e. feature we want to predict), the rest of the features will be used as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rdm_frst.drop('total_reds',axis=1)\n",
    "y = df_rdm_frst.total_reds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since sklearn can't handle categoricals natively, we turn them into dummy variables, as an example for how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list('abca'))\n",
    "print(s)\n",
    "print(pd.get_dummies(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "A random forest aglorith has several hyperaparemeters that can be tweaked to improve its performance, for instance the number of estimators and the maximum number of features to be used in each. We set up a grid search to find the optimum case for out scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': (5,10,50,100),\n",
    "              'max_features': (5,8, 12, 16)\n",
    "             }\n",
    "clf = RandomForestRegressor()\n",
    "grid = RandomizedSearchCV(clf, param_grid, cv=4, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_encoded,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "We can now check the algorithms performance at predicting the player's red cards given these features according to some norm or score. In this case we use the r2 score where a perfect case is a score of 1 and the worst case is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grid.predict(X_encoded)\n",
    "r2_original = metrics.r2_score(y,y_hat)\n",
    "print('Score including the skin tone as a feature: ', r2_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now ignore skin tone\n",
    "We follow the same procedure but now remove the skin tone as a factor and again score the performance at trying to predict how likely a player is to receive red cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpx = X_encoded.skin.values\n",
    "np.random.shuffle(tmpx)\n",
    "X_perm = X_encoded.copy()\n",
    "X_perm.skin = tmpx\n",
    "\n",
    "y_hat_perm = grid.predict(X_perm)\n",
    "r2_perm = metrics.r2_score(y,y_hat_perm)\n",
    "r2_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "The score drops substantially! This is a strong indication that skin tone is playin a role in determining the likelyhood of a player receiving red cards.  There are many other factor we could hope to explore:\n",
    "- Does the referee country/nationality have an effect?\n",
    "- How about including the player position (which we engineered)?\n",
    "- Is there a specific bias towards certain sports clubs? \n",
    "- etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
